# üõ†Ô∏è Gu√≠a Maestra de Soluci√≥n de Problemas: Proyecto Petclinic Automation

Esta gu√≠a exhaustiva recopila los errores cr√≠ticos identificados durante el ciclo de vida del proyecto Petclinic en Kubernetes. Proporciona no solo la soluci√≥n inmediata, sino tambi√©n una inmersi√≥n t√©cnica en las causas ra√≠z y estrategias preventivas para mantener la estabilidad del cl√∫ster.

## 1. Infraestructura y Virtualizaci√≥n (Host)

‚ùå Error: "No usable default provider" o "Kernel module not loaded"

S√≠ntoma: Al ejecutar vagrant up, el sistema devuelve un error indicando que no se encuentra un proveedor v√°lido o que VirtualBox no es usable.

Causa Ra√≠z: Este problema se debe a la ruptura del puente entre el software de virtualizaci√≥n y el Kernel del sistema host. Ocurre principalmente por:

Secure Boot (UEFI): Una medida de seguridad que impide cargar controladores no firmados digitalmente (como los de VirtualBox).

Actualizaciones del Kernel: Al actualizar Ubuntu, los m√≥dulos antiguos de VirtualBox dejan de ser compatibles.

Soluci√≥n Paso a Paso:

Intentar recompilar los m√≥dulos: sudo /sbin/vboxconfig.

Si falla por Secure Boot, seguir el proceso de Enrolamiento MOK: Introducir una contrase√±a temporal, reiniciar, y en la pantalla azul seleccionar "Enroll MOK" -> "Continue" -> "Yes".

Asegurar cabeceras instaladas: sudo apt install dkms linux-headers-$(uname -r).

Implicaci√≥n T√©cnica: Vagrant es una capa de abstracci√≥n; si el proveedor subyacente (VirtualBox) no tiene sus m√≥dulos cargados en el "Ring 0" del procesador, la virtualizaci√≥n por hardware es imposible.

## 2. Registro de Im√°genes y Ciclo de Vida Docker

‚ùå Error: "server gave HTTP response to HTTPS client"

S√≠ntoma: El comando docker push se interrumpe con un fallo de protocolo al intentar subir im√°genes al registro local.

Causa: Por dise√±o, Docker aplica el principio de "Seguridad por Defecto", asumiendo que cualquier registro remoto debe estar cifrado con TLS (HTTPS). Al usar un registro local 10.0.2.15:5000 sin certificados, el cliente Docker rechaza la conexi√≥n.

Soluci√≥n:

Editar o crear /etc/docker/daemon.json e incluir: { "insecure-registries" : ["10.0.2.15:5000"] }.

Reiniciar el demonio: sudo systemctl restart docker.

Consecuencias: Sin esta configuraci√≥n, el flujo CI/CD local se rompe, impidiendo que las im√°genes actualizadas lleguen al cl√∫ster de Kubernetes.

‚ùå Error: "ErrImageNeverPull" o "ImagePullBackOff"

S√≠ntoma: El Pod aparece en Waiting perpetuo. El comando kubectl describe pod muestra fallos de descarga.

Causa: 1.  Inconsistencia de Red: El archivo registries.yaml de K3s no apunta a la IP correcta de la VM.
2.  Im√°genes Inexistentes: El script build.sh fall√≥ silenciosamente (frecuente si el JAR estaba corrupto o incompleto).

Estrategia de Diagn√≥stico: Ejecutar curl -s http://10.0.2.15:5000/v2/_catalog. Si la lista no muestra los 10 microservicios, el problema est√° en la fase de construcci√≥n, no en Kubernetes.

## 3. Red, DNS y Descubrimiento de Servicios

‚ùå Error: "java.net.UnknownHostException: config-server"

S√≠ntoma: El Pod inicia pero colapsa a los pocos segundos. Los logs (kubectl logs) muestran que la aplicaci√≥n Spring Boot no puede localizar la URL del Config Server.

Causa: Spring Cloud utiliza nombres de host l√≥gicos (como http://config-server:8888). Si el servicio de Kubernetes se llama spring-petclinic-config-server, el CoreDNS interno del cl√∫ster no encontrar√° la entrada config-server.

Soluci√≥n de Arquitectura: - Nombres Nativos: Refactorizar el despliegue para usar nombres cortos y directos en los metadatos de Kubernetes (ej. name: config-server).

Esto permite que el Service Discovery de Kubernetes funcione de forma transparente con el de Spring.

Detalle T√©cnico: Kubernetes inyecta sufijos de b√∫squeda DNS (ej. .default.svc.cluster.local). Al usar nombres cortos, garantizamos que la resoluci√≥n sea inmediata y eficiente.

## 4. Gesti√≥n Cr√≠tica de Recursos y Memoria

‚ùå Error: "CrashLoopBackOff" con Exit Code 137 (OOMKilled)

S√≠ntoma: Pods que se reinician aleatoriamente. El estado cambia de Running a Error sin l√≥gica aparente.

Causa: Out Of Memory (OOM). Las aplicaciones Java (JVM) son consumidoras intensivas de RAM. Con 8 microservicios Java m√°s Grafana y Prometheus, los 8GB de la VM est√°n al l√≠mite. Si el consumo total supera la RAM f√≠sica disponible, el kernel de Linux activa el OOM Killer y mata el proceso con mayor consumo (usualmente un servicio de Spring).

Estrategias de Mitigaci√≥n:

L√≠mites en YAML: Definir resources.limits.memory y resources.requests.memory en el template de Kubernetes para evitar que un solo Pod consuma toda la memoria del nodo.

Ajuste de JVM: Pasar variables de entorno como JAVA_OPTS="-Xmx512m -Xms256m" para limitar el heap de Java desde dentro del contenedor.

Despliegue Secuencial: No lanzar todos los YAML a la vez; esperar a que el Config y Discovery Server est√©n estables antes de lanzar el resto.

## 5. Automatizaci√≥n y Contexto de Ejecuci√≥n

‚ùå Error: "k8s-template.yaml: No such file or directory"

S√≠ntoma: Los archivos YAML en k8s-generated/ est√°n vac√≠os o el script deploy-all.sh termina con errores de lectura.

Causa: Vagrant y Ansible ejecutan comandos desde el directorio ra√≠z del usuario (/home/vagrant). Si el script utiliza rutas relativas, no encontrar√° los archivos de apoyo si no se encuentra en el subdirectorio correcto.

Soluci√≥n Profesional: Usar la captura del directorio del script:

cd "$(dirname "$0")" # Cambia el directorio actual a la ubicaci√≥n f√≠sica del script


Lecci√≥n Aprendida: En la automatizaci√≥n de infraestructura, nunca asumas el directorio actual (CWD). Siempre utiliza rutas absolutas o calcula la ruta relativa respecto al script para garantizar la portabilidad entre diferentes entornos de ejecuci√≥n.

Manual de Troubleshooting Expandido - Proyecto Petclinic 2026. Documentaci√≥n de Nivel Senior.

## 6. Conflictos de Ingress y Puertos (K3s)
‚ùå Error: "404 Page Not Found" al acceder por puerto 80

    S√≠ntoma: Connectivity OK (Grafana funciona), pero el acceso a la web principal devuelve 404.

    Causa Ra√≠z: K3s incluye Traefik por defecto como Ingress Controller. Traefik se vincula al puerto 80 de la interfaz de red. Al intentar exponer nuestro api-gateway en el mismo puerto, se produce una colisi√≥n. El 404 es la respuesta por defecto de Traefik al no encontrar rutas (Ingress) definidas.

    Soluci√≥n T√©cnica: 1. Deshabilitar Traefik mediante el flag --disable traefik en la instalaci√≥n de K3s. 2. Asegurar que el servicio api-gateway sea de tipo LoadBalancer.

    Explicaci√≥n: Al desactivar el Ingress por defecto, permitimos que el componente ServiceLB de K3s asigne la IP del nodo directamente a nuestro servicio, convirtiendo al api-gateway en el √∫nico receptor de tr√°fico del puerto 80.

## 7. Verificaci√≥n de Rutas de Microservicios
‚ùå Error: La web carga pero no hay datos de mascotas/veterinarios

    Causa: El API Gateway ha levantado pero los servicios internos (Vets, Customers) a√∫n no han terminado de registrarse en Eureka.

    Soluci√≥n: Los microservicios de Spring Boot tienen un tiempo de "warm-up" de unos 60-90 segundos tras mostrar el estado Running en Kubernetes. Simplemente refresca la p√°gina tras un par de minutos.